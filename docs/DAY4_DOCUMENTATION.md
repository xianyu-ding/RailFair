# Day 4 Documentation - Batch HSP Data Collection ðŸš†

## ðŸ“‹ Overview

Day 4 implements a comprehensive batch data collection system for gathering historical HSP (Historical Service Performance) data across multiple routes and time periods. This implements **Scheme F (Best)** from the planning phase.

## ðŸŽ¯ Objectives

- **Data Volume**: Collect 30,000+ records across 3 phases
- **Route Coverage**: 10 major UK rail routes
- **Time Coverage**: 8 months (Dec 2024 - Jan 2025, Jun-Oct 2025)
- **Data Quality**: Complete validation and statistics

## ðŸ“¦ Files Created

### Configuration Files (3)
1. `hsp_config_phase1.yaml` - Winter historical data (Dec 2024 - Jan 2025)
2. `hsp_config_phase2.yaml` - Recent operational data (Sep-Oct 2025)
3. `hsp_config_phase3.yaml` - Summer baseline data (Jun-Aug 2025)

### Scripts (3)
4. `fetch_hsp_batch.py` - Main batch collection script
5. `validate_hsp_data.py` - Data validation and statistics
6. `run_collection.sh` - Quick start bash script

## ðŸš€ Quick Start

### Prerequisites

```bash
# 1. Set environment variables
export HSP_EMAIL="your_email@example.com"
export HSP_PASSWORD="your_password"

# 2. Ensure required files are present
# - fetch_hsp_batch.py
# - hsp_processor.py (from Day 3)
# - hsp_validator.py (from Day 3)
# - retry_handler.py (from Day 3)
# - hsp_config_phase*.yaml

# 3. Make script executable
chmod +x run_collection.sh
```

### Option 1: Quick Start (Recommended)

```bash
# Run all phases automatically
./run_collection.sh all

# Or run individual phases
./run_collection.sh phase1  # Winter data
./run_collection.sh phase2  # Recent data
./run_collection.sh phase3  # Summer data
```

### Option 2: Manual Execution

```bash
# Phase 1: Winter Historical Data
python3 fetch_hsp_batch.py hsp_config_phase1.yaml --phase "Phase 1: Winter"

# Phase 2: Recent Operational Data
python3 fetch_hsp_batch.py hsp_config_phase2.yaml --phase "Phase 2: Recent"

# Phase 3: Summer Baseline Data
python3 fetch_hsp_batch.py hsp_config_phase3.yaml --phase "Phase 3: Summer"

# Validate collected data
python3 validate_hsp_data.py --db data/railfair.db --output data/report.txt --json data/stats.json
```

## ðŸ“Š Data Collection Plan

### Phase 1: Winter Historical Data (Priority: HIGH)
**Purpose**: Predict winter travel delays (Christmas & New Year season)

```yaml
Date Range: 2024-12-01 to 2025-01-31 (62 days)
Days: WEEKDAY + WEEKEND (all days)
Routes: All 10 routes
Expected Records: ~12,000
Runtime: 3-4 hours
```

**Why Winter Data?**
- Product launches in December 2025
- Users will plan Christmas/New Year travel
- Winter weather impacts delays significantly
- Holiday travel patterns are unique

### Phase 2: Recent Operational Data (Priority: HIGH)
**Purpose**: Reflect current infrastructure and timetable status

```yaml
Date Range: 2025-09-01 to 2025-10-31 (61 days)
Days: WEEKDAY + WEEKEND
Routes: All 10 routes
Expected Records: ~12,000
Runtime: 3-4 hours
```

**Why Recent Data?**
- Most relevant to current operations
- Reflects latest infrastructure changes
- Captures recent service improvements/issues
- Baseline for prediction accuracy

### Phase 3: Summer Baseline Data (Priority: MEDIUM)
**Purpose**: Seasonal comparison and trend analysis

```yaml
Date Range: 2025-06-01 to 2025-08-31 (92 days)
Days: WEEKDAY only (efficiency)
Routes: Top 5 routes only
Expected Records: ~6,500
Runtime: 2 hours
```

**Why Summer Data?**
- Identifies seasonal patterns
- Less weather impact (baseline)
- Compare with winter performance
- Validates prediction models

## ðŸ›¤ï¸ Route Selection

### Tier 1: Major Long-Distance (London-based)
1. **EUS-MAN** - London Euston â†’ Manchester Piccadilly
2. **KGX-EDR** - London King's Cross â†’ Edinburgh
3. **PAD-BRI** - London Paddington â†’ Bristol Temple Meads
4. **LST-NRW** - London Liverpool Street â†’ Norwich
5. **VIC-BHM** - London Victoria â†’ Birmingham New Street

### Tier 2: Regional Inter-City
6. **MAN-LIV** - Manchester Piccadilly â†’ Liverpool Lime Street
7. **BHM-MAN** - Birmingham New Street â†’ Manchester Piccadilly
8. **BRI-BHM** - Bristol Temple Meads â†’ Birmingham New Street

### Tier 3: Scotland & Northern
9. **EDR-GLC** - Edinburgh â†’ Glasgow Central
10. **MAN-LEE** - Manchester Piccadilly â†’ Leeds

**Selection Criteria**:
- High passenger volume
- Frequent service
- Known for delays
- Geographic diversity
- Mix of short/long distance

## ðŸ”§ Features

### Progress Tracking
- **Checkpoint System**: Resume from last completed route
- **Progress File**: `data/progress_phase*.json`
- **Skip Completed**: Automatically skip already collected routes
- **Real-time Status**: Console progress updates

### Error Handling
- **Automatic Retry**: Exponential backoff with jitter
- **Error Classification**: Retryable vs fatal errors
- **Failure Tracking**: Log failed routes for manual review
- **Graceful Degradation**: Continue even if individual routes fail

### Rate Limiting
- **Between Requests**: 1.5s delay
- **Between Routes**: 5s delay
- **Respects API Limits**: 60 requests/minute

### Data Validation
- **Real-time Validation**: Validate before saving
- **Comprehensive Checks**: TOC codes, timestamps, delays
- **Quality Reports**: Identify data quality issues
- **Statistics Generation**: Detailed analysis reports

## ðŸ“ˆ Expected Results

### Total Data Volume
```
Phase 1: 12,000 records
Phase 2: 12,000 records
Phase 3:  6,500 records
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:   30,500 records âœ… (Target: 10,000)
```

### Time Requirements
```
Phase 1: 3-4 hours
Phase 2: 3-4 hours
Phase 3: 2 hours
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:   8-10 hours
```

### Success Criteria (Week 1)
- âœ… Database â‰¥ 10,000 historical records
- âœ… Coverage of 10 major routes
- âœ… Data quality validation passed
- âœ… Statistics cache established

## ðŸ“Š Validation & Statistics

### Automatic Validation
```bash
# Run validation after collection
python3 validate_hsp_data.py --db data/railfair.db

# With output files
python3 validate_hsp_data.py \
    --db data/railfair.db \
    --output data/report.txt \
    --json data/stats.json
```

### Report Includes
- **Basic Statistics**: Record counts, routes, date ranges
- **Route Statistics**: Per-route service counts and TOCs
- **Delay Analysis**: On-time percentage, delay distribution
- **TOC Performance**: Operator-level statistics
- **Temporal Distribution**: By day of week and month
- **Data Quality**: Missing data, duplicates, anomalies
- **Success Criteria**: Week 1 milestone validation

### Example Output
```
===============================================================================
HSP DATA COLLECTION REPORT
===============================================================================

Generated: 2025-11-12 15:30:00
Database: data/railfair.db

===============================================================================
BASIC STATISTICS
===============================================================================

ðŸ“Š Data Overview:
   Service Metrics:  12,450 records
   Service Details:  31,230 records
   Unique Routes:    10
   Unique TOCs:      8

ðŸ“… Date Coverage:
   From: 2024-12-01
   To:   2025-10-31

===============================================================================
DELAY ANALYSIS
===============================================================================

ðŸ“ˆ Overall Performance:
   Total Records:        31,230
   Records with Data:    28,547
   On-Time Count:        21,234
   Delayed Count:        7,313
   On-Time Percentage:   74.4%
   Average Delay:        3.2 minutes

ðŸ“Š Delay Distribution:
   On Time      18234 (63.9%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
   1-5 min       5421 (19.0%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
   6-15 min      3234 (11.3%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
   16-30 min     1214 ( 4.3%) â–ˆâ–ˆ
   >30 min        444 ( 1.6%) â–ˆ

===============================================================================
WEEK 1 SUCCESS CRITERIA CHECK
===============================================================================

âœ… Criteria Met:
   âœ… Historical records â‰¥ 10,000: 31,230
   âœ… Route coverage â‰¥ 10: 10
   âœ… Data quality acceptable: 23 issues

===============================================================================
```

## ðŸ” Monitoring & Debugging

### Real-time Progress
The script provides real-time progress updates:
```
============================================================
ðŸš€ Starting Phase 1: Winter Historical Data
============================================================

ðŸ“Š Collection Plan:
   Total routes: 10
   Date range: 2024-12-01 to 2025-01-31
   Skip completed: True

======================================================================
Route 1/10: EUS-MAN
======================================================================
ðŸ“ Route: EUS-MAN - London Euston - Manchester Piccadilly
ðŸ” Fetching service metrics...
   From: EUS (2024-12-01)
   To: MAN (2025-01-31)
   Days: WEEKDAY,WEEKEND
âœ… Found 1247 services
   Progress: 10/1247 services processed
   Progress: 20/1247 services processed
   ...
âœ… Route EUS-MAN completed in 187.3s
   Records: 1247
   Progress: 1/10 routes
â³ Waiting 5s before next route...
```

### Log Files
```bash
# Collection logs
logs/hsp_phase1_collection.log
logs/hsp_phase2_collection.log
logs/hsp_phase3_collection.log

# Quick start logs
logs/collection_phase1_20251112_150000.log
```

### Progress Files
```bash
# Check progress
cat data/progress_phase1.json

# Example content:
{
  "started_at": "2025-11-12T15:00:00",
  "last_updated": "2025-11-12T16:30:00",
  "completed_routes": ["EUS-MAN", "KGX-EDR", "PAD-BRI"],
  "failed_routes": [],
  "total_records": 3845,
  "phase": "Phase 1: Winter Historical Data"
}
```

## ðŸ› ï¸ Troubleshooting

### Problem: API Authentication Failed
```
Error: 401 Unauthorized
```
**Solution**:
```bash
# Check credentials
echo $HSP_EMAIL
echo $HSP_PASSWORD

# Re-set if needed
export HSP_EMAIL="correct_email@example.com"
export HSP_PASSWORD="correct_password"
```

### Problem: Rate Limited (429)
```
Error: 429 Too Many Requests
```
**Solution**:
```yaml
# Increase delays in config file
data_collection:
  delay_between_requests: 2.0  # Was 1.5
  delay_between_routes: 10.0   # Was 5.0
```

### Problem: Script Interrupted
**Solution**:
```bash
# Resume from last checkpoint
python3 fetch_hsp_batch.py hsp_config_phase1.yaml --phase "Phase 1"
# Script will automatically skip completed routes
```

### Problem: Route Failed
**Solution**:
```bash
# Check failed routes
cat data/progress_phase1.json | grep failed_routes

# Re-run without skipping
python3 fetch_hsp_batch.py hsp_config_phase1.yaml --phase "Phase 1" --no-skip
```

## ðŸ“ Output Files

### Data Files
```
data/
â”œâ”€â”€ railfair.db                    # Main database
â”œâ”€â”€ progress_phase1.json           # Progress tracking
â”œâ”€â”€ progress_phase2.json
â”œâ”€â”€ progress_phase3.json
â”œâ”€â”€ stats_phase1.json             # Collection statistics
â”œâ”€â”€ stats_phase2.json
â”œâ”€â”€ stats_phase3.json
â”œâ”€â”€ validation_report_*.txt       # Validation reports
â”œâ”€â”€ statistics_*.json             # Analysis statistics
â””â”€â”€ raw/hsp/
    â”œâ”€â”€ phase1/                   # Raw JSON responses
    â”œâ”€â”€ phase2/
    â””â”€â”€ phase3/
```

### Log Files
```
logs/
â”œâ”€â”€ hsp_phase1_collection.log
â”œâ”€â”€ hsp_phase2_collection.log
â”œâ”€â”€ hsp_phase3_collection.log
â””â”€â”€ collection_phase*_*.log       # Quick start logs
```

## ðŸ”„ Database Schema

### Tables Updated
```sql
-- Service metrics (summary data)
CREATE TABLE hsp_service_metrics (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    origin TEXT NOT NULL,
    destination TEXT NOT NULL,
    scheduled_departure TEXT,
    scheduled_arrival TEXT,
    toc_code TEXT NOT NULL,
    matched_services_count INTEGER,
    fetch_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(origin, destination, scheduled_departure, scheduled_arrival, toc_code)
);

-- Service details (detailed location data)
CREATE TABLE hsp_service_details (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    rid TEXT NOT NULL,
    date_of_service TEXT NOT NULL,
    toc_code TEXT NOT NULL,
    location TEXT NOT NULL,
    scheduled_departure TIMESTAMP,
    scheduled_arrival TIMESTAMP,
    actual_departure TIMESTAMP,
    actual_arrival TIMESTAMP,
    departure_delay_minutes INTEGER,
    arrival_delay_minutes INTEGER,
    cancellation_reason TEXT,
    fetch_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(rid, location)
);
```

## ðŸ’¡ Best Practices

### Running Collection
1. **Start with Phase 1** - Most important for product launch
2. **Monitor First Route** - Ensure everything works correctly
3. **Use Quick Start Script** - Handles all phases automatically
4. **Run During Off-Peak** - Reduce API congestion
5. **Validate After Each Phase** - Catch issues early

### Error Handling
1. **Don't Panic on Errors** - Script retries automatically
2. **Check Progress File** - See what's completed
3. **Review Failed Routes** - Investigate specific issues
4. **Re-run if Needed** - Use --no-skip to retry

### Data Quality
1. **Validate Immediately** - Run validation after collection
2. **Review Statistics** - Check for anomalies
3. **Compare Phases** - Ensure consistency
4. **Document Issues** - Note any data quality problems

## ðŸ“š Next Steps (Day 5)

After successful Day 4 collection:

1. **Data Validation** (Day 5)
   - KB metadata integration
   - TOC compensation rules
   - Cross-validation

2. **Statistical Pre-calculation** (Day 6-7)
   - On-time percentages per route
   - Delay distributions
   - Seasonal patterns
   - Cache in database

3. **Documentation Update**
   - Update data structure docs
   - Record lessons learned
   - Plan Week 2 tasks

## ðŸŽ“ Lessons Learned

### What Worked Well
- âœ… Progress tracking prevents data loss
- âœ… Rate limiting avoids API issues
- âœ… Validation catches problems early
- âœ… Phased approach allows flexibility

### What to Improve
- âš ï¸ Add parallel processing (future)
- âš ï¸ Implement data deduplication
- âš ï¸ Add more granular logging
- âš ï¸ Create web dashboard for monitoring

## ðŸ“ Configuration Reference

### Key Settings

```yaml
# API Configuration
api:
  base_url: "https://hsp-prod.rockshore.net/api/v1"
  timeout: 30

# Collection Parameters
data_collection:
  from_date: "2024-12-01"
  to_date: "2025-01-31"
  days: "WEEKDAY,WEEKEND"
  num_services: 500
  delay_between_requests: 1.5
  delay_between_routes: 5.0

# Retry Strategy
retry:
  max_attempts: 3
  initial_delay: 1.0
  max_delay: 30.0
  backoff_multiplier: 2
  jitter: true
```

### Environment Variables
```bash
# Required
HSP_EMAIL or HSP_USERNAME
HSP_PASSWORD

# Optional
LOG_LEVEL=INFO
DATABASE_PATH=data/railfair.db
```

## ðŸŽ‰ Success Indicators

Day 4 is successful when:
- âœ… All 3 phases completed
- âœ… Database has >30,000 records
- âœ… All 10 routes covered
- âœ… Data quality validation passes
- âœ… Statistics report generated
- âœ… No critical errors in logs

---

**Created**: 2025-11-12  
**Status**: Ready for execution  
**Estimated Runtime**: 8-10 hours total  
**Expected Records**: 30,500+

ðŸš‚ **Ready to collect data!** Run `./run_collection.sh all` to start.
