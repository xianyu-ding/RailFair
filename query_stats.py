#!/usr/bin/env python3
"""
RailFair Statistics Query Interface - Day 6
æä¾›å¿«é€Ÿçš„ç»Ÿè®¡æŸ¥è¯¢æ¥å£ï¼Œæ”¯æŒç¼“å­˜
"""

import sqlite3
import json
from datetime import datetime, date
from typing import Dict, List, Optional, Tuple
import hashlib

class StatisticsQuery:
    """ç»Ÿè®¡æŸ¥è¯¢æ¥å£"""
    
    def __init__(self, db_path: str = "data/railfair.db"):
        self.db_path = db_path
        self.conn = None
        self.cache_hits = 0
        self.cache_misses = 0
    
    def connect(self):
        """è¿æ¥æ•°æ®åº“"""
        self.conn = sqlite3.connect(self.db_path)
        self.conn.row_factory = sqlite3.Row
    
    def close(self):
        """å…³é—­è¿æ¥"""
        if self.conn:
            self.conn.close()
    
    def __enter__(self):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        self.connect()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        self.close()
    
    # ============================================================================
    # è·¯çº¿ç»Ÿè®¡æŸ¥è¯¢
    # ============================================================================
    
    def get_route_stats(self, origin: str, destination: str, 
                       use_latest: bool = True) -> Optional[Dict]:
        """
        è·å–è·¯çº¿ç»Ÿè®¡
        
        Args:
            origin: å‡ºå‘ç«™ä»£ç 
            destination: åˆ°è¾¾ç«™ä»£ç 
            use_latest: æ˜¯å¦ä½¿ç”¨æœ€æ–°ç»Ÿè®¡ï¼ˆTrueï¼‰æˆ–æŒ‡å®šæ—¥æœŸ
        
        Returns:
            ç»Ÿè®¡å­—å…¸æˆ–None
        """
        cursor = self.conn.cursor()
        
        if use_latest:
            cursor.execute("""
                SELECT * FROM route_statistics
                WHERE origin = ? AND destination = ?
                ORDER BY calculation_date DESC
                LIMIT 1
            """, (origin, destination))
        else:
            cursor.execute("""
                SELECT * FROM route_statistics
                WHERE origin = ? AND destination = ?
                ORDER BY calculation_date DESC
            """, (origin, destination))
        
        result = cursor.fetchone()
        
        if result:
            stats = dict(result)
            # è§£æJSONå­—æ®µ
            if stats.get('hourly_stats'):
                stats['hourly_stats'] = json.loads(stats['hourly_stats'])
            if stats.get('day_of_week_stats'):
                stats['day_of_week_stats'] = json.loads(stats['day_of_week_stats'])
            return stats
        
        return None
    
    def get_all_routes_stats(self, order_by: str = 'reliability_score') -> List[Dict]:
        """
        è·å–æ‰€æœ‰è·¯çº¿çš„æœ€æ–°ç»Ÿè®¡
        
        Args:
            order_by: æ’åºå­—æ®µ (reliability_score, on_time_percentage, avg_delay_minutes)
        
        Returns:
            ç»Ÿè®¡åˆ—è¡¨
        """
        cursor = self.conn.cursor()
        
        valid_orders = ['reliability_score', 'on_time_percentage', 'avg_delay_minutes']
        if order_by not in valid_orders:
            order_by = 'reliability_score'
        
        order_direction = 'DESC' if order_by != 'avg_delay_minutes' else 'ASC'
        
        cursor.execute(f"""
            SELECT * FROM v_latest_route_stats
            ORDER BY {order_by} {order_direction}
        """)
        
        return [dict(row) for row in cursor.fetchall()]
    
    def get_best_routes(self, limit: int = 5) -> List[Dict]:
        """è·å–æœ€å¯é çš„è·¯çº¿"""
        cursor = self.conn.cursor()
        
        cursor.execute("""
            SELECT * FROM v_latest_route_stats
            ORDER BY reliability_score DESC
            LIMIT ?
        """, (limit,))
        
        return [dict(row) for row in cursor.fetchall()]
    
    def get_worst_routes(self, limit: int = 5) -> List[Dict]:
        """è·å–æœ€ä¸å¯é çš„è·¯çº¿"""
        cursor = self.conn.cursor()
        
        cursor.execute("""
            SELECT * FROM v_latest_route_stats
            ORDER BY reliability_score ASC
            LIMIT ?
        """, (limit,))
        
        return [dict(row) for row in cursor.fetchall()]
    
    # ============================================================================
    # TOCç»Ÿè®¡æŸ¥è¯¢
    # ============================================================================
    
    def get_toc_stats(self, toc_code: str, use_latest: bool = True) -> Optional[Dict]:
        """è·å–TOCè¿è¥å•†ç»Ÿè®¡"""
        cursor = self.conn.cursor()
        
        if use_latest:
            cursor.execute("""
                SELECT * FROM toc_statistics
                WHERE toc_code = ?
                ORDER BY calculation_date DESC
                LIMIT 1
            """, (toc_code,))
        else:
            cursor.execute("""
                SELECT * FROM toc_statistics
                WHERE toc_code = ?
                ORDER BY calculation_date DESC
            """, (toc_code,))
        
        result = cursor.fetchone()
        
        if result:
            stats = dict(result)
            if stats.get('route_performance'):
                stats['route_performance'] = json.loads(stats['route_performance'])
            return stats
        
        return None
    
    def get_all_tocs_stats(self, order_by: str = 'reliability_score') -> List[Dict]:
        """è·å–æ‰€æœ‰TOCç»Ÿè®¡"""
        cursor = self.conn.cursor()
        
        valid_orders = ['reliability_score', 'ppm_5_percentage', 'cancelled_percentage']
        if order_by not in valid_orders:
            order_by = 'reliability_score'
        
        order_direction = 'DESC' if order_by != 'cancelled_percentage' else 'ASC'
        
        cursor.execute(f"""
            SELECT * FROM v_latest_toc_stats
            ORDER BY {order_by} {order_direction}
        """)
        
        return [dict(row) for row in cursor.fetchall()]
    
    def get_best_tocs(self, limit: int = 5) -> List[Dict]:
        """è·å–æœ€å¯é çš„è¿è¥å•†"""
        cursor = self.conn.cursor()
        
        cursor.execute("""
            SELECT * FROM v_latest_toc_stats
            ORDER BY reliability_score DESC
            LIMIT ?
        """, (limit,))
        
        return [dict(row) for row in cursor.fetchall()]
    
    # ============================================================================
    # æ—¶æ®µç»Ÿè®¡æŸ¥è¯¢
    # ============================================================================
    
    def get_time_slot_stats(self, origin: str, destination: str, 
                           hour: int, day_of_week: Optional[int] = None) -> Optional[Dict]:
        """
        è·å–ç‰¹å®šæ—¶æ®µçš„ç»Ÿè®¡
        
        Args:
            origin: å‡ºå‘ç«™
            destination: åˆ°è¾¾ç«™
            hour: å°æ—¶ (0-23)
            day_of_week: æ˜ŸæœŸ (0=Monday, 6=Sunday, None=æ‰€æœ‰)
        """
        cursor = self.conn.cursor()
        
        if day_of_week is not None:
            cursor.execute("""
                SELECT * FROM time_slot_statistics
                WHERE origin = ? AND destination = ?
                  AND hour_of_day = ? AND day_of_week = ?
                ORDER BY calculation_date DESC
                LIMIT 1
            """, (origin, destination, hour, day_of_week))
        else:
            cursor.execute("""
                SELECT * FROM time_slot_statistics
                WHERE origin = ? AND destination = ?
                  AND hour_of_day = ? AND day_of_week IS NULL
                ORDER BY calculation_date DESC
                LIMIT 1
            """, (origin, destination, hour))
        
        result = cursor.fetchone()
        return dict(result) if result else None
    
    # ============================================================================
    # é¢„æµ‹ç¼“å­˜æŸ¥è¯¢
    # ============================================================================
    
    def generate_cache_key(self, origin: str, destination: str, 
                          departure_date: str, departure_time: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_str = f"{origin}|{destination}|{departure_date}|{departure_time}"
        return hashlib.md5(key_str.encode()).hexdigest()
    
    def get_prediction_cache(self, origin: str, destination: str,
                            departure_date: str, departure_time: str) -> Optional[Dict]:
        """
        ä»ç¼“å­˜è·å–é¢„æµ‹ç»“æœ
        
        Returns:
            é¢„æµ‹å­—å…¸æˆ–Noneï¼ˆç¼“å­˜æœªå‘½ä¸­æˆ–å·²è¿‡æœŸï¼‰
        """
        cache_key = self.generate_cache_key(origin, destination, departure_date, departure_time)
        
        cursor = self.conn.cursor()
        cursor.execute("""
            SELECT * FROM prediction_cache
            WHERE cache_key = ?
              AND (expires_at IS NULL OR expires_at > datetime('now'))
        """, (cache_key,))
        
        result = cursor.fetchone()
        
        if result:
            self.cache_hits += 1
            
            # æ›´æ–°è®¿é—®æ¬¡æ•°å’Œæ—¶é—´
            cursor.execute("""
                UPDATE prediction_cache
                SET hit_count = hit_count + 1,
                    last_accessed = datetime('now')
                WHERE cache_key = ?
            """, (cache_key,))
            self.conn.commit()
            
            stats = dict(result)
            if stats.get('alternative_suggestions'):
                stats['alternative_suggestions'] = json.loads(stats['alternative_suggestions'])
            
            return stats
        else:
            self.cache_misses += 1
            return None
    
    def save_prediction_cache(self, prediction: Dict, ttl_hours: int = 24):
        """
        ä¿å­˜é¢„æµ‹åˆ°ç¼“å­˜
        
        Args:
            prediction: é¢„æµ‹å­—å…¸
            ttl_hours: ç¼“å­˜å­˜æ´»æ—¶é—´ï¼ˆå°æ—¶ï¼‰
        """
        cache_key = self.generate_cache_key(
            prediction['origin'],
            prediction['destination'],
            prediction['departure_date'],
            prediction['departure_time']
        )
        
        cursor = self.conn.cursor()
        
        # è®¡ç®—è¿‡æœŸæ—¶é—´
        expires_at = datetime.now().replace(microsecond=0)
        from datetime import timedelta
        expires_at += timedelta(hours=ttl_hours)
        
        # å‡†å¤‡æ•°æ®
        data = {
            'cache_key': cache_key,
            'origin': prediction['origin'],
            'destination': prediction['destination'],
            'departure_date': prediction['departure_date'],
            'departure_time': prediction['departure_time'],
            'predicted_delay_minutes': prediction.get('predicted_delay_minutes'),
            'on_time_probability': prediction.get('on_time_probability'),
            'delay_5_probability': prediction.get('delay_5_probability'),
            'delay_15_probability': prediction.get('delay_15_probability'),
            'severe_delay_probability': prediction.get('severe_delay_probability'),
            'confidence_level': prediction.get('confidence_level'),
            'confidence_score': prediction.get('confidence_score'),
            'recommendation': prediction.get('recommendation'),
            'alternative_suggestions': json.dumps(prediction.get('alternative_suggestions', [])),
            'model_version': prediction.get('model_version', 'v1-statistical'),
            'expires_at': expires_at.isoformat()
        }
        
        # åˆ é™¤æ—§ç¼“å­˜ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        cursor.execute("DELETE FROM prediction_cache WHERE cache_key = ?", (cache_key,))
        
        # æ’å…¥æ–°ç¼“å­˜
        columns = ', '.join(data.keys())
        placeholders = ', '.join(['?' for _ in data])
        
        cursor.execute(f"""
            INSERT INTO prediction_cache ({columns})
            VALUES ({placeholders})
        """, list(data.values()))
        
        self.conn.commit()
    
    def clean_expired_cache(self) -> int:
        """æ¸…ç†è¿‡æœŸç¼“å­˜ï¼Œè¿”å›æ¸…ç†æ•°é‡"""
        cursor = self.conn.cursor()
        
        cursor.execute("""
            DELETE FROM prediction_cache
            WHERE expires_at < datetime('now')
        """)
        
        deleted = cursor.rowcount
        self.conn.commit()
        
        return deleted
    
    # ============================================================================
    # æ•°æ®è´¨é‡æŸ¥è¯¢
    # ============================================================================
    
    def get_data_quality_metrics(self, metric_date: Optional[str] = None) -> Optional[Dict]:
        """è·å–æ•°æ®è´¨é‡æŒ‡æ ‡"""
        cursor = self.conn.cursor()
        
        if metric_date:
            cursor.execute("""
                SELECT * FROM data_quality_metrics
                WHERE metric_date = ?
            """, (metric_date,))
        else:
            cursor.execute("""
                SELECT * FROM data_quality_metrics
                ORDER BY metric_date DESC
                LIMIT 1
            """)
        
        result = cursor.fetchone()
        return dict(result) if result else None
    
    # ============================================================================
    # åˆ†æå’Œæ¯”è¾ƒ
    # ============================================================================
    
    def compare_routes(self, routes: List[Tuple[str, str]]) -> List[Dict]:
        """
        æ¯”è¾ƒå¤šæ¡è·¯çº¿
        
        Args:
            routes: [(origin1, dest1), (origin2, dest2), ...]
        
        Returns:
            å¯¹æ¯”åˆ—è¡¨
        """
        results = []
        
        for origin, dest in routes:
            stats = self.get_route_stats(origin, dest)
            if stats:
                results.append({
                    'route': f"{origin}-{dest}",
                    'reliability_score': stats['reliability_score'],
                    'reliability_grade': stats['reliability_grade'],
                    'ppm_5': stats['time_to_5_percentage'],
                    'ppm_10': stats['time_to_10_percentage'],
                    'avg_delay': stats['avg_delay_minutes'],
                    'cancelled_pct': stats['cancelled_percentage']
                })
        
        return sorted(results, key=lambda x: x['reliability_score'], reverse=True)
    
    def get_cache_stats(self) -> Dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        cursor = self.conn.cursor()
        
        # æ€»ç¼“å­˜æ•°
        cursor.execute("SELECT COUNT(*) as total FROM prediction_cache")
        total = cursor.fetchone()['total']
        
        # æœ‰æ•ˆç¼“å­˜æ•°
        cursor.execute("""
            SELECT COUNT(*) as valid 
            FROM prediction_cache
            WHERE expires_at > datetime('now')
        """)
        valid = cursor.fetchone()['valid']
        
        # è¿‡æœŸç¼“å­˜æ•°
        expired = total - valid
        
        # å¹³å‡å‘½ä¸­æ¬¡æ•°
        cursor.execute("""
            SELECT AVG(hit_count) as avg_hits
            FROM prediction_cache
            WHERE expires_at > datetime('now')
        """)
        avg_hits = cursor.fetchone()['avg_hits'] or 0
        
        # ç¼“å­˜å‘½ä¸­ç‡
        total_requests = self.cache_hits + self.cache_misses
        hit_rate = (self.cache_hits / total_requests * 100) if total_requests > 0 else 0
        
        return {
            'total_entries': total,
            'valid_entries': valid,
            'expired_entries': expired,
            'avg_hits_per_entry': round(avg_hits, 2),
            'cache_hit_rate': round(hit_rate, 2),
            'cache_hits': self.cache_hits,
            'cache_misses': self.cache_misses
        }
    
    def print_route_stats(self, origin: str, destination: str):
        """æ‰“å°è·¯çº¿ç»Ÿè®¡ï¼ˆæ ¼å¼åŒ–ï¼‰"""
        stats = self.get_route_stats(origin, destination)
        
        if not stats:
            print(f"âŒ No statistics found for route {origin}-{destination}")
            return
        
        print(f"\n{'='*60}")
        print(f"ğŸ“Š Route Statistics: {stats['route_name']}")
        print(f"{'='*60}")
        
        print(f"\nğŸ“ˆ Performance Metrics:")
        print(f"  Reliability Grade:    {stats['reliability_grade']} ({stats['reliability_score']:.1f}/100)")
        print(f"  On Time (â‰¤1 min):     {stats['on_time_percentage']:.1f}%")
        print(f"  PPM-5 (â‰¤5 min):       {stats['time_to_5_percentage']:.1f}%")
        print(f"  PPM-10 (â‰¤10 min):     {stats['time_to_10_percentage']:.1f}%")
        print(f"  Average Delay:        {stats['avg_delay_minutes']:.1f} minutes")
        print(f"  Cancellation Rate:    {stats['cancelled_percentage']:.1f}%")
        
        print(f"\nğŸ“Š Data Coverage:")
        print(f"  Date Range:           {stats['data_start_date']} to {stats['data_end_date']}")
        print(f"  Total Services:       {stats['total_services']:,}")
        print(f"  Sample Size:          {stats['sample_size']:,}")
        print(f"  Data Quality:         {stats['data_quality_score']:.1f}/100")
        
        print(f"\nâ±ï¸  Delay Distribution:")
        print(f"  0-5 min:              {stats['delays_0_5_count']:,} ({stats['delays_0_5_count']/stats['sample_size']*100:.1f}%)")
        print(f"  5-15 min:             {stats['delays_5_15_count']:,} ({stats['delays_5_15_count']/stats['sample_size']*100:.1f}%)")
        print(f"  15-30 min:            {stats['delays_15_30_count']:,} ({stats['delays_15_30_count']/stats['sample_size']*100:.1f}%)")
        print(f"  30-60 min:            {stats['delays_30_60_count']:,} ({stats['delays_30_60_count']/stats['sample_size']*100:.1f}%)")
        print(f"  >60 min:              {stats['delays_60_plus_count']:,} ({stats['delays_60_plus_count']/stats['sample_size']*100:.1f}%)")
        
        print(f"\nğŸ“… Last Updated:        {stats['last_updated']}")


def main():
    """æ¼”ç¤ºæŸ¥è¯¢åŠŸèƒ½"""
    import sys
    
    db_path = "data/railfair.db" if len(sys.argv) == 1 else sys.argv[1]
    
    with StatisticsQuery(db_path) as query:
        print("ğŸ” RailFair Statistics Query Demo\n")
        
        # è·å–æ‰€æœ‰è·¯çº¿
        print("ğŸ“Š All Routes (by reliability):")
        print("-" * 60)
        routes = query.get_all_routes_stats()
        
        if routes:
            for r in routes:
                print(f"{r['route_name']:<15} Grade: {r['reliability_grade']:<3} "
                      f"PPM-5: {r['ppm_5']:>5.1f}% PPM-10: {r['ppm_10']:>5.1f}%")
            
            # è¯¦ç»†æ˜¾ç¤ºç¬¬ä¸€æ¡è·¯çº¿
            first_route = routes[0]
            query.print_route_stats(first_route['origin'], first_route['destination'])
        else:
            print("  No statistics available yet. Run calculate_stats.py first.")
        
        # TOCç»Ÿè®¡
        print(f"\n\nğŸ¢ All TOCs (by reliability):")
        print("-" * 60)
        tocs = query.get_all_tocs_stats()
        
        if tocs:
            for t in tocs:
                print(f"{t['toc_code']:<8} Grade: {t['reliability_grade']:<3} "
                      f"PPM-5: {t['ppm_5']:>5.1f}% Cancel: {t['cancelled_percentage']:>5.1f}%")
        
        # ç¼“å­˜ç»Ÿè®¡
        print(f"\n\nğŸ’¾ Cache Statistics:")
        print("-" * 60)
        cache_stats = query.get_cache_stats()
        print(f"  Total Entries:        {cache_stats['total_entries']}")
        print(f"  Valid Entries:        {cache_stats['valid_entries']}")
        print(f"  Expired Entries:      {cache_stats['expired_entries']}")
        print(f"  Avg Hits per Entry:   {cache_stats['avg_hits_per_entry']:.1f}")

if __name__ == "__main__":
    main()
